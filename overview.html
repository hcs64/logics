<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Modal logics, temporal and dynamic</title>

<style>
div.subbody {
  max-width:960px;
  margin-left:auto;
  margin-right:auto;
  font-family:serif;
}
img {
  display: block;
  margin-left:auto;
  margin-right:auto;
}
dfn {
  font-style:italic;
}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: { inlineMath: [['$','$']] }
});
</script>

<!--<script type="text/javascript" src="MathJax-2.4-latest/MathJax.js?config=TeX-AMS_HTML"></script>-->

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

</head>

<body>
<div class="subbody">
<h1>Modal logics, temporal and dynamic</h1>
<small>Adam Gashlin</small>

<h2>Contents</h2>
<ul>
<li><a href="#intro">Propositional logic</a></li>
<li><a href="#modal">Modal logic</a></li>
<li><a href="#temporal">Temporal logic</a></li>
<li><a href="#dynamic">Dynamic logic</a></li>
</ul>

<h2>Overview</h2>
<p>
This report deals with a branch of formal logic called
Modal Logic, in which we are concerned with the truth of propositions in
different situations, and how those situations relate to each other logically.
Example situations include points in time, conceivable worlds,
believable knowledge, and states of a computation.</p>
<p>
There is a good deal of theoretical mechanism that applies equally well to many
kinds of Modal Logic, such as a the unifying Kripke semantics. The essential
core of Kripke semantics is a binary relation on the situational
&quot;worlds&quot;, which defines how propositions in one world may be
incorporated by propositions in another. This report examines in detail two
particular families of modal logic, Temporal Logic and Dynamic Logic.
</p>
<p>
In temporal logic truth is given for particular points in time.
Times are related by
&quot;<i>s</i> is in the past of <i>t</i>&quot; and
&quot;<i>s</i> is in the future of <i>t</i>&quot;.
We can express statements with reference to some or all
times, future or past, such as
&quot;<i>p</i> or <i>q</i> will be true&quot; or
&quot;if <i>r</i> was always true, <i>r</i> is true&quot;.
These are useful, for instance, for verifying the eventual proper behavior of
programs,
invariants such as &quot;if the operating system gets a request, the request
will be granted&quot;.
</p>

<p>
In dynamic logic, truths hold for states of an executing program,
and the relations are the input/output relation of each program.
This lets us express such statements as
&quot;when program <i>a</i> finishes, <i>p</i> is true&quot; and
&quot;if <i>p</i> or <i>q</i> are true, then when program <i>b</i> finishes, <i>q</i> is true&quot;.
This can be useful for formally specifying correctness properties, such as
&quot;if <i>a</i> is positive before the loop, <i>a</i> is zero after the loop
terminates&quot;.
</p>

<hr>

<h2 id="intro">Propositional logic</h2>
<h3>Formal logic</h3>
<p>
Our concern in a formal logic is to abstract away every detail that is not
necessary for preserving the validity of statements. Much reasoning is valid on
a formal level: a properly formed argument is assured to be valid by virtue of
its form.
This abstraction allows logicians to study the structure of logic apart from
dealing with the specifics of arguments, and it encourages attention to the
essential details of a situation.
</p>
<p>
Most of the operations of formal logic can be executed mechanically, to varying
degrees of effectiveness. There can be great practical value in expressing a
problem in the terms of a logic, if there are efficient automatic methods
available.
</p>

<h3>Propositions</h3>
<p>
A <dfn>proposition</dfn> is simply a statement which we regard as true or
false.
An <dfn>atomic proposition</dfn> is defined to have no internal structure
that we are interested in.
</p>
<p>
Consider the two atomic propositions
</p>
<ul>
<li><i>p</i> = &quot;My pants are blue&quot;</li>
<li><i>q</i> = &quot;My hair is black&quot;</li>
</ul>
<p>
By calling these atomic, we are ignoring as irrelevant any common details,
such as that both of these statements are about me and involve colors.
An atomic proposition only has an identity, like the letters <i>p</i> and
<i>q</i> here, which lets us know whether propositions can be considered
identical.</p>

<h3>Connectives</h3>
<p>
In propositional logic, we reduce statements to atomic propositions, joined by
a small family of connectives into larger propositions.
If we wanted a proposition that means &quot;my pants are blue and my hair is
black&quot;, we might introduce a new atomic proposition called <i>s</i>, but
this would be a poor choice.
For instance, it would allow us to make the statement
&quot;<i>s</i>, but not <i>p</i>&quot;. This is never true given the earlier
definition of <i>p</i> (it is a <dfn>contradiction</dfn>),
but that is not clear from the form of the statement.
</p>
<p>
Instead of <i>s</i>, we can call this proposition $p \wedge q$.
The propositional connective $\wedge$ in the middle is read as &quot;and&quot;, and the combined proposition is the statement &quot;both <i>p</i> and <i>q</i>
are true&quot;.
</p>
<p>
By using this standard method of connecting existing propositions to name a
new one, we get a name that is much more useful. If we know that both
proposition <i>p</i> and proposition <i>q</i> are true, we automatically know
that proposition $p \wedge q$ is true, without having to look up any details
about what these propositions mean.
Likewise the contradiction from earlier would be expressed as
&quot;$p \wedge q$ but not <i>p</i>&quot;, in which the
contradiction is immediately apparent.
</p>

<h4>Implication</h4>
<p>
An important connective is &quot;implies&quot;, written as
$\rightarrow$. This is used to write
propositions such as &quot;if it is noon, the sun is up&quot;.
Note that implication doesn't say that two statements are always the same;
it is quite possible for the sun to be up when it isn't noon. The only strong
claim made by $p \rightarrow q$ is that <em>when</em> <i>p</i> is true,
<i>q</i> is also true. Therefore $p \rightarrow q$ is only false when
<i>p</i> is true and <i>q</i> is false.
</p>

<h4>Parenthesis</h4>
<p>
Consider a proposition $a \vee b \wedge c$. How is this to be interpreted?
We could consider the whole proposition to be of the form
$a \vee X$, where the <i>X</i> is $b \wedge c$.
On the other hand it seems that we could just as well consider it to be
$X \wedge c$ where <i>X</i> is $a \vee b$. These interpretations give
different meanings to the proposition, for instance
when <i>a</i> = true, <i>b</i> = true, <i>c</i> = false, the first
interpretation is true and the second is false.
</p>
<p>
We eliminate these issues of ambiguity by adding parenthesis around parts of the
expression that are to be considered as a unit. For instance, if we had
instead written $(a \vee b) \wedge c$, we would be insisting on an
interpretation where 
the proposition is of the form $X \wedge c$, where <i>X</i> is $(a \vee b)$.
The alternative $a \vee X$ wouldn't make sense:
for one thing $a \vee X$ doesn't have a place for the left parenthesis,
for another the $X$ would have to be $b) \wedge c$, with a lonely right
parenthesis.
</p>
<p>
To summarize, we put a pair of parenthesis around a proposition 
to &quot;wrap&quot; it, so that any interpretation has to &quot;unwrap&quot;
it as a whole rather than breaking it
up and giving parts to surrounding expressions.
</p>
<p>
As a side note, parenthesis are only necessary because we are using
<dfn>infix</dfn> notation, where connectives are written in between the
propositions they connect, like $a \vee b$. An alternative is <dfn>postfix</dfn>
notation, where the connectives are written afterwards, such as $a\: b \vee$.
This form is unambiguous, as the connectives always connect the two previous
units in the expression. For example the two different interpretations of
$a \vee b \wedge c$ are written in postfix as
$a\: b\: c \wedge \vee$ (for $a \vee (b \wedge c)$) and
$a b \vee c \wedge$ (for $(a \vee b) \wedge c$). The problem is
that postfix is considered unintuitive and difficult to read,
so we stick with infix.
</p>

<h3>Evaluation</h3>
<p>
We haven't said yet what color my hair or pants actually are. There are some
statements whose truth doesn't depend on the truth of the atomic propositions,
for instance contradictions are always false and their opposite,
<dfn>tautologies</dfn>, are always true.
But for everything else,
the truth value of a proposition depends on
the truth values of the atomic propositions it is made from.
</p>

<p>
The process of determining the truth value is <dfn>evaluation</dfn>, and it
proceeds according to the structure of a statement. For a statement like the
$p \wedge q$ we have been considering, consult the <dfn>truth table</dfn>
for $\wedge$ below.
</p>

<div style="display:inline-block; margin-left:1em; margin-right:1em;">
$$
{\large \wedge} \\

\begin{array}{c|c|c} \varphi &amp; \psi &amp; \varphi \wedge \psi \\ \hline
\text{T} &amp; \text{T} &amp; \text{T} \\ \hline
\text{T} &amp; \text{F} &amp; \text{F} \\ \hline
\text{F} &amp; \text{T} &amp; \text{F} \\ \hline
\text{F} &amp; \text{F} &amp; \text{F} 
\end{array}
$$
</div>

<div style="display:inline-block; margin-left:1em; margin-right:1em;">
$${\large \vee} \\

\begin{array}{c|c|c} \varphi &amp; \psi &amp; \varphi \vee \psi \\ \hline
\text{T} &amp; \text{T} &amp; \text{T} \\ \hline
\text{T} &amp; \text{F} &amp; \text{T} \\ \hline
\text{F} &amp; \text{T} &amp; \text{T} \\ \hline
\text{F} &amp; \text{F} &amp; \text{F} 
\end{array}
$$
</div>

<div style="display:inline-block; margin-left:1em; margin-right:1em;">
$${\large \rightarrow} \\

\begin{array}{c|c|c} \varphi &amp; \psi &amp; \varphi \rightarrow \psi \\ \hline
\text{T} &amp; \text{T} &amp; \text{T} \\ \hline
\text{T} &amp; \text{F} &amp; \text{F} \\ \hline
\text{F} &amp; \text{T} &amp; \text{T} \\ \hline
\text{F} &amp; \text{F} &amp; \text{T} 
\end{array}
$$
</div>

<div style="display:inline-block; margin-left:1em; margin-right:1em;">
$${\large \neg} \\

\begin{array}{c|c} \varphi &amp; \neg \varphi \\ \hline
\text{T} &amp; \text{F} \\ \hline
\text{F} &amp; \text{T}
\end{array}$$
</div>

<p>The Greek letters $\varphi$ (phi) and $\psi$ (psi) here are used to indicate
any proposition, not just an atomic proposition.
In $p \wedge q$, $\varphi = p$ and $\psi = q$. If $\varphi$ is <b>T</b>rue and $\psi$ is <b>F</b>alse, $\varphi \wedge \psi$ is <b>F</b>alse.</p>

<p>
The benefit of this method over saying &quot;$\wedge$ is 'and'&quot; is
that the table leaves no room for interpretation. While there may not be many
ways of interpreting &quot;and&quot;, consider &quot;or&quot;, which is written
as $\vee$ in propositional logic, and which has the truth table shown above.
</p>
<p>
In English it is not unusual for &quot;x or y&quot; to exclude the case where
both x and y are true, but the truth table tells us unambiguously that
$\varphi$ <b>T</b>rue and $\psi$ <b>T</b>rue makes $\varphi \vee \psi$ <b>T</b>rue.
</p>

<p>Consider a more complicated statement such as
$(\neg p \wedge q) \vee (p \wedge \neg q)$.
First off, $\neg q$ means &quot;not q&quot;, which has the truth table above.
At this point it is helpful to think of each of the atomic propositions
<i>p</i> and <i>q</i> as simply something that can be true or false.
If we say that <i>p</i> is true and <i>q</i> is false, this forms our
<dfn>model</dfn> for the state of the world, our model is formed from the
<dfn>valuation</dfn> &quot;<i>p</i> is true, <i>q</i> is false&quot;.
To evaluate $(\neg p \wedge q) \vee (p \wedge \neg q)$, we break it down until
we arrive at statements whose truth can be determined directly from the model,
then we build back up to the full statement. This can be pictured as building
a tree 
<br><br>
<img src="xor_tree_build.png" alt="a tree is constructed from the analysis of a proposition">
<br><br>
and filling it with truth values.
<br><br>
<img src="xor_tree_eval.png" alt="truth values propagate from the leaves of a tree">

Thus for this model, with the valuation
&quot;<i>p</i> is true, <i>q</i> is false&quot;, 
$(\neg p \wedge q) \vee (p \wedge \neg q)$ is true.
</p>

<h3>Evaluation by definition of $M \vDash \varphi$</h3>

<p>
Formally, we treat evaluation as extending the valuation to cover all possible
propositions formed from the atomic propositions. 

If a proposition $\varphi$ is true in model <i>M</i>, we write
$M \vDash \varphi$.
<br><br>
$
\begin{align}
M &amp; \vDash p &amp;&amp;
\text{ if $p$ is a true atomic proposition} \\

M &amp; \vDash \neg \varphi &amp;&amp;
\text{ if $M \vDash \varphi$ is not true} \\

M &amp; \vDash \varphi \wedge \psi &amp;&amp;
\text{ if $M \vDash \varphi$ and $M \vDash \psi$} \\

M &amp; \vDash \varphi \vee \psi &amp;&amp;
\text{ if one or both of $M \vDash \varphi$ and $M \vDash \psi$}
\end{align}
$
<br><br>
Note that only one of these rules applies for every possible proposition,
so if the left hand side matches the form of a proposition but the condition on 
the right hand side doesn't hold, then the proposition is false. If
$M \vDash \varphi$ is false, we write $M \not \vDash \varphi$.
</p>

<hr>

<h2 id="modal">Modal logic</h2>

<h3>Multiple states</h3>
<p>
So far everything discussed holds for classical propositional logic as well as
modal logic.
The first place where modal logic differs is that a model can have multiple
<dfn>states</dfn>, a.k.a. &quot;situations&quot; or &quot;worlds&quot;,
whereas classical propositional logic considers only one set of truths at a
time.
</p>
<p>
As an example, say we have one state, call it <i>s</i>, where the atomic
propositions <i>p</i> and <i>q</i> are both true.
We also have a state <i>t</i>, where only <i>p</i> is true
and <i>q</i> is false.
In modal logic a model <i>M</i> has at least two components: the set of states
$S_M$ and a valuation $V_M$.
In the example, $S_M = \{s,t\}$, the two states, and $V_M$ is a
function that gives the atomic propositions that are true in a specified state:
$V_M(s) = \{p,q\}$ and $V_M(t) = \{p\}$.
</p>
<p>
To show that we are discussing truths in a particular state <i>s</i>, we write
$M \vDash_s$ instead of simply $M \vDash$. In the running example,
$M \vDash_s p$ and $M \vDash_s q$, as well as $M \vDash_t p$. However it is not
the case that $M \vDash_t q$, so we write $M \not{\vDash_t} q$. We can also
use the earlier definition of $\vDash$ to extend $\vDash_s$ and $\vDash_t$ to
larger propositions, for instance $M \vDash_s p \wedge q$ and $M \vDash_t p \wedge \neg q$.
</p>
<p>
Often we want to reason without knowing what state is the
&quot;real world&quot;.
If we find a proposition that is true across all states, we can use it without
reference to a particular state.
If this is so we say the proposition is <dfn>true in the model</dfn>,
and we write $M \vDash \varphi$ without a subscript.
In the example we have $M \vDash p$ and $M \vDash q \vee p$, for instance.
</p>

<h3>Referring to other states</h3>
<p>
The real power of modal logic comes from being able to make reference to
other states.
For this purpose we add two symbols to our proposition language:
$\newcommand{\box}{{\scriptsize \square}} \box$ (&quot;box&quot;) and $\diamond$, (&quot;diamond&quot;). These are used to prefix
other propositions to modify their interpretation.
$\box \varphi$ means that in all related states (to be defined in the next
section),
$\varphi$ is true, whereas $\diamond \varphi$ asserts that there is at least one
related state where $\varphi$ is true.
</p>
<p>
Note that $\box \varphi$ and $\diamond \varphi$ are only about related
states, they make no reference to what is true in the current state. To claim
that $\varphi$ is true in the current state and in all related states, use the
proposition $\varphi \wedge \box \varphi$.
Also note that $\box \varphi$ can be true even if there are no states where
$\varphi$ is true; this is the case when there are no related states.
</p>
<p>
We can formally define $\box$ and $\diamond$ by adding the following rules to
our definition of $\vDash$:
<br><br>
$
\begin{align}
M &amp; \vDash_s \box \varphi &amp;&amp;
\text{ if for all states $t$ where $sR_{M}t$, $M \vDash_t \varphi$ } \\
M &amp; \vDash_s \diamond \varphi &amp;&amp;
\text{ if there is a state $t$ such that $sR_{M}t$ and $M \vDash_t \varphi$ }
\end{align}
$
<br><br>

$sR_{M}t$ means that <i>s</i> is related to <i>t</i> by relation $R_{M}$, which we
will explain in the next section.

</p>

<h3>Related states</h3>
<p>
The meaning of $\box$ and $\diamond$ in a given model is specified by a binary
relation between pairs of states.
A <dfn>binary relation</dfn> is simply a set of ordered pairs of objects.
The term &quot;binary&quot; here means that the relation deals with
two objects at a time, i.e. it is about pairs.
If a relation <i>R</i> contains a pair of states, then those states are
considered to be related by <i>R</i>.
For example the relation $R = \{(s,t),(s,u),(t,u),(u,t)\}$ means that
<i>s</i> is related to <i>t</i> by <i>R</i>,
which we write as <i>sRt</i>. The
converse is not true, however: it is not the case that <i>tRs</i> (as there is
no pair $(t,s)$). Both <i>tRu</i> and <i>uRt</i> are true.
</p>
<!--
<p>
For an example of a relation that does not hold in both directions, consider
&quot;to the right of&quot;. <i>s</i> cannot be to the right
of <i>t</i> if <i>t</i> is to the right of <i>s</i>, only one of these can be
true. In fact neither of them could be true if neither is to the right of the
other.
</p>-->
<p>
One way to understand the meaning of a relation in a model is that is
describes the set of states that are accessible, by $\box$ and $\diamond$,
from a given state. $M \vDash_s \box q$ only refers to the truth of <i>q</i>
in those states <i>t</i> that are related to <i>s</i> by $sR_{M}t$.
<br>
More on this in the examples below.
</p>

<img src="modal_example_1.png" style="float:right; margin:1em;" alt="interconnected circles representing the model">

<h4>An example</h4>
<p>
For a simple example (based on Harel et al. exercise 5.1),
consider a model with the states $S_M$, relation $R_M$, and truth values
determined by $V_M$:<br>
$S_M = \{s,t,u\}$,<br>
$R_M = \{(s,t),(s,u),(t,u),(u,t)\}$,<br>
$V_M(s) = \{\}, V_M(t)=\{p, q\}$,<br>
$V_M(u)=\{p\}$.<br>
</p>
<p>
This is depicted in the diagram on the right, where circled letters are states,
arrows show relations, and colored shapes enclose states where the like-colored
propositions are true.
</p>
<p>Here, we have $M \vDash_x \box p$ for any state <i>x</i>,
as all states <i>y</i> that <i>x</i> is related to
(i.e. that it has an arrow from x to y) have $M \vDash_y p$. Therefore we can
write $M \vDash \box p$.</p>
<p>We also have $M \vDash_s \diamond q$ and $M \vDash_u \diamond q$, but not
$M \vDash_t \diamond q$.</p>
<p>$M \vDash_t \diamond \diamond q$ is true, as
there is some state (<i>u</i>) related from <i>t</i> that relates to some state
(<i>t</i> again) where <i>q</i> is true.</p>

<h3 style="clear:both">Frames</h3>

<p>
A proposition can be true in one state of a model, or it can be true across all
states in the model. Then there are tautologies such as $p \vee \neg p$, which
are true regardless of model, as they are true regardless of the truth values of
the atomic propositions.
In between propositions that are and that are true in a model,
there is another level of propositions that are <dfn>valid in a frame</dfn>.
</p>
<ol>
<li>$\varphi$ is true in a state <i>s</i> in a model <i>M</i>, $M \vDash_s \varphi$</li>
<li>$\varphi$ is true in a model <i>M</i>, true in all states of the model, $M \vDash \varphi$</li>
<li>$\varphi$ is valid in a frame <i>F</i>, true on all models on a frame, $F \vDash \varphi$</li>
<li>$\varphi$ is a tautology, valid regardless of frame, $\vDash \varphi$</li>
</ol>
<p>
A <dfn>frame</dfn> consists of just the set of states $S_M$ and the relation
$R_M$ used to construct the model, that is it does not specify what the truth
values actually are in the states. The propositions that are valid on a frame
thus depend on the properties of the relation. Some examples follow
(from Goldblatt, p. 12, theorem 1.12).
</p>
<dl id="frame_properties">
<dt>Reflexivity</dt>
<dd>
If a relation says that a state is always related to itself (<i>sRs</i> for all
states <i>s</i>, the relation is called <dfn>reflexive</dfn>. In any frame that
has a reflexive relation, all propositions of the form
$\box \varphi \rightarrow \varphi$ will be valid. If all related states have
$\varphi$ true, then this state must have $\varphi$ true as well, since it is
related to itself.
</dd>

<dt>Symmetry</dt>
<dd>
In a symmetric relation <i>R</i>, if <i>sRt</i> then <i>tRs</i>, so all
relations go both directions. In a frame with a symmetric relation,
all propositions
of the form $\varphi \rightarrow \box \diamond \varphi$ are true. That is,
if $\varphi$ is true at <i>s</i>, then in every state <i>t</i> related to
<i>s</i>, there is some related state <i>u</i> where $\varphi$ is true. To see
why this is true, <i>u</i> can just be <i>s</i> since both
<i>sRt</i> and <i>tRs</i>.
</dd>

<dt>Transitivity</dt>
<dd>
<img src="transitive.png" style="float:right; margin:1em;">
A transitive relation is always &quot;inherited&quot; through a middle state.
If <i>sRt</i> and <i>tRu</i>, then, if <i>R</i> is a transitive relation, it is 
also the case that <i>sRu</i>. This allows the middle state to be cut out so
that the relation applies directly between two states that are otherwise known
to be second-degree related.
<br><br>
In a frame with a transitive relation, all propositions with the form
$\box \varphi \rightarrow \box \box \varphi$ are valid. This is because, as
shown on the right, all states that are second-degree related (such as <i>u</i>)
are also first-degree related (because of transitivity), thus if all
first-degree related states have $\varphi$ (i.e. $\box \varphi$), then all
second-degree related states have $\varphi$ (i.e. $\box \box \varphi$).
</dd>

<dt style="clear:right;">Seriality</dt>
<dd>
A serial relation is usually on an infinite set, like a set of points in time
that we assume will go on for ever; seriality is the property that any
state always has a related state. In a frames with a serial relation, all
propositions with the form $\box \varphi \rightarrow \diamond \varphi$ are
valid.
This is simply the statement that we don't have any dead ends where there are
no related states, where $\box \varphi$ can be true without $\varphi$ actually
being true anywhere (because &quot;all related states&quot; is nothing).
</dd>
</dl>

<hr>

<h2 id="temporal">Temporal logic</h2>
<h3>A time-dependent logic</h3>
<p>
Temporal logic is a branch of modal logic which supports
propositions that are true at one time yet are false at another.
Moreover, because this is a full-featured
modal logic, propositions at some time can make reference to other
times. Thus we can give the proposition <i>p</i> for &quot;the machine is
working&quot;, $\diamond p$ for &quot;at some point in the future the machine
will work&quot;, and $\box p$ for &quot;the machine will work at all times in
the future&quot;.
</p>

<p>
In a temporal logic model
<i>M</i>, we consider the states of the model $S_M$ to be points in time,
and the relation $R_M$ is defined between two points in time, one of which is
before the other. $s R_M t$ means <i>s</i> is before <i>t</i>,
therefore <i>t</i> is in the future of <i>s</i>.
Those propositions which are true at a time <i>s</i> are given by $V_M(s)$, as
in modal logic in general.
</p>

<h3>Properties of the temporal relation</h3>
<p>
Let's consider a few of the
<a href="#frame_properties">properties of relations</a> mentioned above,
and whether they should apply to our model of time.
It is normally the case that we do not want to consider the present as part of
the future, which is to say the relation $R_M$ is not reflexive, in fact it is
<dfn>irreflexive</dfn> as no time relates to itself.
We also insist that times only have one order, so $s R_M t$ and $t R_M s$ can't
both be true. This makes $R_M$ not symmetric, indeed it is
a combination of the irreflexive property and the <dfn>antisymmetric</dfn>
property, which states that <i>sRt</i> and <i>tRs</i> only if <i>s = t</i>.
These properties, irreflexivity and antisymmetry, do not correspond to valid
propositions across frames, unlike reflexivity and symmetry do
(Goldblatt p. 14).
</p>
<p>
We probably also want $R_M$ to have seriality,
to ensure that time goes on forever.
</p>


<p>
Transitivity is an important property that $R_M$ must have if <i>M</i> is to
make sense as a model of time. A transitive relation means that
$s R_M t \wedge t R_M u \rightarrow s R_M u$, so a point in the future of the
future is in the future of the present. It would make little sense that a point
further in the future would not still be in the future.
</p>
<h4>Connectedness</h4>
<p>
These properties aren't enough to narrow down a unique interpretation of time,
however. For one thing, we haven't made any claim that every time is comparable
to every other, i.e. while we have said that not both
$s R_M t$ and $t R_M s$ are true (a combination of antisymmetry and
irreflexivity),
it is possible that neither are true.
This allows unconnected sections of the timeline, which have no relation
to other sections. It also raises the possibility of branching time: there may 
be more than one possible future for a given point in time.
</p>
<p>
If we do make the requirement that exactly one of $s R_M t$ or $t R_M s$ are
true, except in the case when <i>s = t</i> (in which case both are false because
of irreflexivity), then $R_M$ fits most of our intuitions about time. It behaves
like the &quot;less than&quot; relation on numbers, so we can consider the
states of the model to each have a unique &quot;clock&quot;.
</p>

<h3>Variations of temporal logic</h3>
<h4>Diodorean</h4>
If we instead allow $R_M$ to be reflexive, we are dealing with the
&quot;Diodorean Modality&quot; (Goldblatt pg. 44).
This forces us to consider the present to be part of the future, so what will
always be true must currently be true.

<h4>Two-way</h4>
<p>
Often it is the case that we want to talk about times that are in the past as
well as times that are in the future. We can do this by introducing another
relation that is the converse (every pair is reversed) of the relation we have
dealt with so far. We then also have two sets of modal connectives, instead of
just $\diamond$ and $\box$. These are $[F]$ and $\langle F \rangle$ for the
future, and $[P]$ and $\langle P \rangle$ for the past.
</p>

<h4>Non-discrete</h4>
<p>
In an analysis of computation, we probably want to think of time as a series of
instants, one following another. But in more general analyses of time, it may be
desirable to assume that between any two distinct instants there is another.
</p>
<p>
There are several possible models of non-discrete time.
Time could behave like the rational numbers,
which can be indexed by the integers, or like the real
numbers, which cannot. The distinction between real and rational time is only
relevant with if we are using the two-way temporal logic described above;
with only a future modality, they behave identically
(Goldblatt ex. 6.4 and 8.8).
</p>

<hr>

<h2 id="dynamic">Dynamic logic</h2>
<p>This section is largely drawn from Harel et al. Chapter 5.</p>

<h3>A logic for change</h3>
<p>
Dynamic logic is about expressing the means of change between the states of a
system, and how truths can be related between the states. Typically we think of
programs changing the state of a computer.
There are many (infinitely many) relations in dynamic logic, and each one
represents the behavior of a particular program. These relations are completely
arbitrary, in particular a program may relate one input state to several output
states, which represents nondeterminism (i.e. multiple possible outcomes).
We may use nondeterminism because there are truly unpredictable behaviors at
work, or because it is preferable to not overspecify exactly what will happen.
</p>

<p>
A set of arbitrary relations is not a very effective representation of
programming: while a program can be thought of as some mapping of inputs
to outputs, it is usually constructed from a few primitive operations combined
into a larger program. Programming languages provide constructs like loops and
conditional statements to facilitate combining smaller parts in well-structured
ways. Dynamic logic supports this view by providing ways to construct programs
by combining other programs and by incorporating propositions.
</p>

<h4>Halting</h4>
<p>
If we expect an output from a program, we require that program to
<dfn>halt</dfn>, i.e. to finish with a state we consider to be
the output.
Programs may not halt, which may be considered as reaching some error condition
or simply running forever without producing a result.
Dynamic logic inherently supports this behavior.
Failing to halt on some input is indicated by a program relation
mapping some input state to zero output states.
</p>

<h3>Syntax</h3>
<p>
At its heart, a dynamic logic is based on some set of primitive programs, these
will just be the relations of the modal logic. For example we will call two
programs <i>a</i> and <i>b</i>. Programs can be combined in
several ways, and each combination is itself a program.
</p>
<ul>
<li>A <dfn>sequence</dfn>, written <i>a ; b</i>,
runs program <i>a</i> and then program <i>b</i>.</li>
<li>A <dfn>choice</dfn>, written $a \cup b$,
nondeterministically runs either <i>a</i> or <i>b</i>.</li>
<li>An <dfn>iteration</dfn>, written $a^*$,
runs program <i>a</i> a nondeterministic number of times, 0 or more.</li>
</ul>

<p>
When we want to make propositions about what is true after running a program, we
write the program as a modal connective, like the modal connectives $\box$ and
$\diamond$ that we had in the basic modal logic language discussed earlier.
For instance we write
$\langle a \rangle$ (like $\diamond$) if we are stating what is true
after <em>some</em> run of program <i>a</i>, or $[a]$ (like $\box$) if we are
stating what is true after <em>all</em> runs of the program.
</p>

<p>
Thus we can make statements like
$\varphi \rightarrow [ a ; b^* ] \varphi$, meaning &quot;if
$\varphi$ is true, then after running <i>a</i> and then running <i>b</i> any
number of times, $\varphi$ will be true&quot;. One interesting proposition is
$[\alpha^*]\varphi \rightarrow [\alpha ; \alpha^*]\varphi$, which states that
if running $\alpha$ any number of times results in $\varphi$ true, then running
it at least once (once plus any number of times) results in $\varphi$ true; this
is true of any program $\alpha$ and any proposition $\varphi$.
</p>

<p>
As an example of choice, $\langle a \cup (b;b) \rangle \varphi$
means that if we consider running program <i>a</i> once or program <i>b</i>
twice, at least one of these will result in $\varphi$.
</p>

<p>
We will usually use the $[\alpha]$ form, as we are interested in
what will necessarily be true after the program halts, but as noted we need
to be careful that the program actually does halt.
</p>

<h4>Tests</h4>
<p>
There is one other way to make a program in dynamic logic: If $\varphi$ is a
proposition, $\varphi ?$ is a program. This type of program is a
<dfn>test</dfn>, and it can be understood as doing nothing when the proposition
is true, thus the relation for $\varphi ?$ relates input states where $\varphi$ 
is true to identical outputs.
However, if the proposition is false, the relation maps to no
outputs, thus the program does not halt. This means that $[ \varphi ? ] \varphi$
is always true; either</p>
<ul>
<li>$\varphi$ was true and thus it is still true after $\varphi ?$ (as it
relates to the same output state), or</li>
<li>$\varphi$ was false so $\varphi ?$ doesn't halt (and
thus relates to no output state,
so $[\varphi?] \psi$ is true for any $\psi$)</li>
</ul>

<p>
Consider a program that runs the program <i>a</i>
only if proposition <i>p</i> is true first, otherwise it does nothing. Perhaps
it is not necessary or safe to run <i>a</i> if <i>p</i> is false.
We can write the true part easily enough as <i>p? ; a</i>, which will halt with
the result of running <i>a</i> if <i>p</i> was true (assuming <i>a</i> halts),
but this will not halt if <i>p</i> is false.
On the other hand $\neg p ?$ will halt when <i>p</i>
is false, without changing the state, but it will not halt when <i>p</i> is
true.
We can make this dilemma work with a choice: $(p? ; a) \cup \neg p$. The $\cup$
makes a program that tries one of the two branches, and as we have established
only one of them will halt for a given truth value of <i>p</i>. As the choice is
nondeterministic, the combined program will always halt, having run one of the
two possibilities.
</p>

<h3>Formal semantics</h3>
<p>
Formally we provide the following rules for determining the truth of
propositions in dynamic logic:
<br>
$
\begin{align}
M &amp; \vDash_s p &amp;&amp;
\text{ if $p$ is in $V_M(s)$} \\

M &amp; \vDash_s \neg \varphi &amp;&amp;
\text{ if $M \not {\vDash_s} \varphi$} \\

M &amp; \vDash_s \varphi \rightarrow \psi &amp;&amp;
\text{ if $M \vDash_s \varphi$ implies $M \vDash_s \psi$} \\

M &amp; \vDash_s \langle \alpha \rangle \varphi &amp;&amp;
\text{ if there is some $t$ such that $s(R\alpha)t$ and $M \vDash_t \varphi$} \\

M &amp; \vDash_s [ \alpha ] \varphi &amp;&amp;
\text{ if for all $t$, if $s(R\alpha)t$, then $M \vDash_t \varphi$}
\end{align}
$
</p>

<p>
(Note: $\vee$ and $\wedge$ can be defined in terms of $\rightarrow$ and $\neg$).
</p>
<p>
$R\pi$ is the relation for a program $\pi$. $R\pi$ is defined for all
non-primitive programs with the following rules, where $\alpha$ and $\beta$ are
programs:
<br>
$
\begin{align}
&amp; s (R\alpha ; \beta) t &amp;&amp;
\text{ if for some $u$, $s(R\alpha)u$ and $u(R\beta)t$} \\

&amp; s (R\alpha \cup \beta) t &amp;&amp;
\text{ if $s (R\alpha) t$ or $s (R\beta) t$} \\

&amp; s (R\alpha^*) t &amp;&amp;
\text{ if $s = t$ or $s (R\alpha ; \alpha^*) t$} \\

&amp; s (R\varphi?) s &amp;&amp;
\text{ if } M \vDash_s \varphi

\end{align}
$
</p>

<h3>While programs</h3>
<p>
It is possible to express real programs in the language of
dynamic logic, but often we want to use something closer to the programming
languages in common use. The &quot;while&quot; language is one such
way of expressing programs more intuitively. We will show how while language
programs can be converted into dynamic logic.
</p>
<dl>
<dt>primitives</dt>
<dd>
We start with primitive programs that work like those in dynamic logic, they
make some change to the program state. These aren't defined any more
specifically by the language, the particular problem situation must specify the
primitive programs that all larger programs are constructed from.
</dd>
<dt>sequence</dt>
<dd>
As with dynamic logic, we can write a program that runs program <i>x</i>
and then program <i>y</i> as <i>x ; y</i>. This syntax is identical to the
equivalent dynamic logic program.</dd>
<dt>conditional</dt>
<dd>
The while language has a conditional statement of the form
<i>if p then x else y</i>. If the proposition <i>p</i> is true then the
program <i>x</i> is executed, if instead <i>p</i> is false then the
program <i>y</i> is executed.
The dynamic logic program $(p? ; x) \cup (\neg p ? ; y)$ will accomplish the
same thing, we saw a similar example earlier when introducing tests.
</dd>
<dt>loop</dt>
<dd>
The main loop construct in a while program is, naturally, <i>while</i>. We write
<i>while p do x</i> to test proposition <i>p</i>,
if it is false then the loop is finished,
otherwise we run <i>x</i> and repeat from the test.

This is expressed in dynamic logic as $(p? ; x)^* ; \neg p?$. The iterative part
($(p? ; x)^*$) will test <i>p</i> (not progressing if <i>p</i> is false) and
run <i>x</i>, repeatedly.
We then need the extra &quot;guard&quot; test $\neg p?$ to prevent any early
exit from the loop; since the iterative part is nondeterministic, it could run 0
times or any number of times until <i>p</i> becomes false, we want it to
run exactly as many times as it takes for <i>p</i> to become false.
</dd>
</dl>

<hr>
<h3>Bibliography</h3>
<ul>
<li>Robert Goldblatt. 1992. <u>Logics of Time and Computation</u>.</li>
<li>David Harel, Jerzy Tiuryn, and Dexter Kozen. 2000. <u>Dynamic Logic</u>.</li>
<li>B. Mishra. 2013 (unpublished). <a href="http://cs.nyu.edu/mishra/COURSES/13.LOGIC/13.logic.html">Logic In Computer Science</a> lecture notes.</li>
</ul>

</div>
</body>
</html>
